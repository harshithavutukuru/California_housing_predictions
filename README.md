Regression Model Comparison — Decision Tree, Random Forest, XGBoost & LightGBM

This project demonstrates how to build, tune, and compare the performance of four popular regression algorithms — 
Decision Tree Regressor, Random Forest Regressor, XGBoost Regressor, and LightGBM Regressor — using the California Housing dataset.

The goal of this project is to:

Compare the predictive power of different tree-based regression models.

Understand the impact of boosting vs bagging methods.

Apply hyperparameter tuning to improve model accuracy.

Visualize and interpret the model performances.
